{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, LassoCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    mean_squared_error,\n",
    "    accuracy_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"joined_data.csv\")\n",
    "\n",
    "\n",
    "data = data.drop([\"id\", \"name\", \"release_date\", \"year\", \"mode\", 'duration_ms', 'liveness', 'key'], axis = 1)\n",
    "X = data.iloc[:,:-1]\n",
    "y = data[\"new_genres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['classical', 'jazz', 'rock', 'country', 'pop', 'edm', 'hip hop',\n",
       "       'alternative', 'metal'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"new_genres\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size = 0.25, random_state = 42)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train = np.array(X)[train_index]\n",
    "    X_test = np.array(X)[test_index]\n",
    "    y_train = np.array(y)[train_index]\n",
    "    y_test = np.array(y)[test_index]\n",
    "    \n",
    "X_train = preprocessing.scale(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/Documents/Northeastern/Spring 2020/ECE2300/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.4223660367589956\n",
      "Train Error: 0.5776339632410044\n",
      "Train Recall: 0.4223660367589956\n",
      "Train Precision: 0.35918780820368224\n",
      "-----------------------------------------\n",
      "Test Accuracy: 0.25103729836472966\n",
      "Test Error: 0.7489627016352703\n",
      "Test Recall: 0.25103729836472966\n",
      "Test Precision: 0.22873837863022153\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Log regression with Lasso penalty\n",
    "\n",
    "clf = LogisticRegression(random_state=0, penalty='l1', solver='liblinear')\n",
    "#clf = LassoCV(cv=5, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)\n",
    "\n",
    "test_pred = clf.predict(X_test)\n",
    "train_pred = clf.predict(X_train)\n",
    "test_acc = (accuracy_score(test_pred, y_test))\n",
    "test_error = 1 - test_acc\n",
    "train_acc = (accuracy_score(train_pred, y_train))\n",
    "train_error = (1 - train_acc)\n",
    "test_prec = precision_score(y_test, test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "train_prec = precision_score(y_train, train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Train Error:\", train_error)\n",
    "print(\"Train Recall:\", train_recall)\n",
    "print(\"Train Precision:\", train_prec)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Error:\", test_error)\n",
    "print(\"Test Recall:\", test_recall)\n",
    "print(\"Test Precision:\", test_prec)\n",
    "print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/Documents/Northeastern/Spring 2020/ECE2300/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.4106061166376983\n",
      "Train Error: 0.5893938833623017\n",
      "Train Recall: 0.4106061166376983\n",
      "Train Precision: 0.32030464689854315\n",
      "-----------------------------------------\n",
      "Test Accuracy: 0.25842596906964876\n",
      "Test Error: 0.7415740309303512\n",
      "Test Recall: 0.25842596906964876\n",
      "Test Precision: 0.2062431762427709\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Log. Regression with Cross Validation and Lasso\n",
    "\n",
    "clf = LogisticRegressionCV(cv=5, random_state=0, penalty='l1', solver='liblinear')\n",
    "#clf = LassoCV(cv=5, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)\n",
    "\n",
    "test_pred = clf.predict(X_test)\n",
    "train_pred = clf.predict(X_train)\n",
    "test_acc = (accuracy_score(test_pred, y_test))\n",
    "test_error = 1 - test_acc\n",
    "train_acc = (accuracy_score(train_pred, y_train))\n",
    "train_error = (1 - train_acc)\n",
    "test_prec = precision_score(y_test, test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "train_prec = precision_score(y_train, train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Train Error:\", train_error)\n",
    "print(\"Train Recall:\", train_recall)\n",
    "print(\"Train Precision:\", train_prec)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Error:\", test_error)\n",
    "print(\"Test Recall:\", test_recall)\n",
    "print(\"Test Precision:\", test_prec)\n",
    "print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "n_classifiers = [10, 50, 100]\n",
    "\n",
    "for n in n_classifiers:\n",
    "    ada = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth = 5), \n",
    "        n_estimators = n, learning_rate = 1, random_state = 1)\n",
    "    ada.fit(X_train, y_train)\n",
    "    test_pred = ada.predict(X_test)\n",
    "    train_pred = ada.predict(X_train)\n",
    "    test_acc = (accuracy_score(test_pred, y_test))\n",
    "    test_error = 1 - test_acc\n",
    "    train_acc = (accuracy_score(train_pred, y_train))\n",
    "    train_error = (1 - train_acc)\n",
    "    test_prec = precision_score(y_test, test_pred, average='weighted')\n",
    "    test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "    train_prec = precision_score(y_train, train_pred, average='weighted')\n",
    "    train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "    print(n, \"Classifiers:\")\n",
    "    print(\"Test Accuracy:\", test_acc)\n",
    "    print(\"Test Error:\", test_error)\n",
    "    print(\"Test Recall:\", test_recall)\n",
    "    print(\"Test Precision:\", test_prec)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Train Accuracy:\", train_acc)\n",
    "    print(\"Train Error:\", train_error)\n",
    "    print(\"Train Recall:\", train_recall)\n",
    "    print(\"Train Precision:\", train_prec)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Estimators:\n",
      "Test Accuracy: 0.298320353236149\n",
      "Test Error: 0.701679646763851\n",
      "-----------------------------------------\n",
      "Train Accuracy: 0.7128360637550386\n",
      "Train Error: 0.2871639362449614\n",
      "-----------------------------------------\n",
      "Feature ranking:\n",
      "1. feature 5 (0.140858)\n",
      "2. feature 0 (0.128512)\n",
      "3. feature 6 (0.118112)\n",
      "4. feature 1 (0.117211)\n",
      "5. feature 4 (0.111341)\n",
      "6. feature 2 (0.102256)\n",
      "7. feature 8 (0.100891)\n",
      "8. feature 7 (0.093006)\n",
      "9. feature 3 (0.087813)\n",
      "\n",
      "\n",
      "Index(['acousticness', 'danceability', 'energy', 'instrumentalness',\n",
      "       'loudness', 'popularity', 'speechiness', 'tempo', 'valence'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance\n",
    "n_trees = [50]#, 100, 150, 300, 500]\n",
    "\n",
    "for n in n_trees:\n",
    "    rf = RandomForestClassifier(n_estimators = n).fit(X_train, y_train)\n",
    "    test_pred = rf.predict(X_test)\n",
    "    train_pred = rf.predict(X_train)\n",
    "    test_acc = (accuracy_score(test_pred, y_test))\n",
    "    test_error = 1 - test_acc\n",
    "    train_acc = (accuracy_score(train_pred, y_train))\n",
    "    train_error = (1 - train_acc)\n",
    "    #test_prec = precision_score(y_test, test_pred)\n",
    "    #test_recall = recall_score(y_test, test_pred)\n",
    "    #train_prec = precision_score(y_train, train_pred)\n",
    "    #train_recall = recall_score(y_train, train_pred)\n",
    "    print(n, \"Estimators:\")\n",
    "    print(\"Test Accuracy:\", test_acc)\n",
    "    print(\"Test Error:\", test_error)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Train Accuracy:\", train_acc)\n",
    "    print(\"Train Error:\", train_error)\n",
    "    print(\"-----------------------------------------\")\n",
    "\n",
    "    importances = rf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X_train.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "    print(\"\\n\")\n",
    "    print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#np.delete(X_test, [5,6], axis = 0)\n",
    "#X_test\n",
    "n_trees = [50]#, 100, 150, 300, 500]\n",
    "\n",
    "for n in n_trees:\n",
    "    rf = RandomForestClassifier(n_estimators = n).fit(X_train, y_train)\n",
    "    test_pred = rf.predict(X_test)\n",
    "    train_pred = rf.predict(X_train)\n",
    "    test_acc = (accuracy_score(test_pred, y_test))\n",
    "    test_error = 1 - test_acc\n",
    "    train_acc = (accuracy_score(train_pred, y_train))\n",
    "    train_error = (1 - train_acc)\n",
    "    print(n, \"Estimators:\")\n",
    "    print(\"Test Accuracy:\", test_acc)\n",
    "    print(\"Test Error:\", test_error)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Train Accuracy:\", train_acc)\n",
    "    print(\"Train Error:\", train_error)\n",
    "    print(\"-----------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier().fit(X_train, y_train)\n",
    "\n",
    "test_pred = nn.predict(X_test)\n",
    "train_pred = nn.predict(X_train)\n",
    "test_acc = (accuracy_score(test_pred, y_test))\n",
    "test_error = 1 - test_acc\n",
    "train_acc = (accuracy_score(train_pred, y_train))\n",
    "train_error = (1 - train_acc)\n",
    "test_prec = precision_score(y_test, test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "train_prec = precision_score(y_train, train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Train Error:\", train_error)\n",
    "print(\"Train Recall:\", train_recall)\n",
    "print(\"Train Precision:\", train_prec)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Error:\", test_error)\n",
    "print(\"Test Recall:\", test_recall)\n",
    "print(\"Test Precision:\", test_prec)\n",
    "print(\"-----------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier().fit(X_train, y_train)\n",
    "\n",
    "test_pred = nn.predict(X_test)\n",
    "train_pred = nn.predict(X_train)\n",
    "test_acc = (accuracy_score(test_pred, y_test))\n",
    "test_error = 1 - test_acc\n",
    "train_acc = (accuracy_score(train_pred, y_train))\n",
    "train_error = (1 - train_acc)\n",
    "test_prec = precision_score(y_test, test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "train_prec = precision_score(y_train, train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Train Error:\", train_error)\n",
    "print(\"Train Recall:\", train_recall)\n",
    "print(\"Train Precision:\", train_prec)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Error:\", test_error)\n",
    "print(\"Test Recall:\", test_recall)\n",
    "print(\"Test Precision:\", test_prec)\n",
    "print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/Documents/Northeastern/Spring 2020/ECE2300/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.46833327169853184\n",
      "Train Error: 0.5316667283014682\n",
      "Train Recall: 0.46833327169853184\n",
      "Train Precision: 0.4501132072157608\n",
      "-----------------------------------------\n",
      "Test Accuracy: 0.03421420488584171\n",
      "Test Error: 0.9657857951141583\n",
      "Test Recall: 0.03421420488584171\n",
      "Test Precision: 0.0533647179980828\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier().fit(X_train, y_train)\n",
    "\n",
    "test_pred = nn.predict(X_test)\n",
    "train_pred = nn.predict(X_train)\n",
    "test_acc = (accuracy_score(test_pred, y_test))\n",
    "test_error = 1 - test_acc\n",
    "train_acc = (accuracy_score(train_pred, y_train))\n",
    "train_error = (1 - train_acc)\n",
    "test_prec = precision_score(y_test, test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "train_prec = precision_score(y_train, train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Train Error:\", train_error)\n",
    "print(\"Train Recall:\", train_recall)\n",
    "print(\"Train Precision:\", train_prec)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Error:\", test_error)\n",
    "print(\"Test Recall:\", test_recall)\n",
    "print(\"Test Precision:\", test_prec)\n",
    "print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier().fit(X_train, y_train)\n",
    "\n",
    "test_pred = nn.predict(X_test)\n",
    "train_pred = nn.predict(X_train)\n",
    "test_acc = (accuracy_score(test_pred, y_test))\n",
    "test_error = 1 - test_acc\n",
    "train_acc = (accuracy_score(train_pred, y_train))\n",
    "train_error = (1 - train_acc)\n",
    "test_prec = precision_score(y_test, test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "train_prec = precision_score(y_train, train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Train Error:\", train_error)\n",
    "print(\"Train Recall:\", train_recall)\n",
    "print(\"Train Precision:\", train_prec)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Error:\", test_error)\n",
    "print(\"Test Recall:\", test_recall)\n",
    "print(\"Test Precision:\", test_prec)\n",
    "print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier().fit(X_train, y_train)\n",
    "\n",
    "test_pred = nn.predict(X_test)\n",
    "train_pred = nn.predict(X_train)\n",
    "test_acc = (accuracy_score(test_pred, y_test))\n",
    "test_error = 1 - test_acc\n",
    "train_acc = (accuracy_score(train_pred, y_train))\n",
    "train_error = (1 - train_acc)\n",
    "test_prec = precision_score(y_test, test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "train_prec = precision_score(y_train, train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Train Error:\", train_error)\n",
    "print(\"Train Recall:\", train_recall)\n",
    "print(\"Train Precision:\", train_prec)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Error:\", test_error)\n",
    "print(\"Test Recall:\", test_recall)\n",
    "print(\"Test Precision:\", test_prec)\n",
    "print(\"-----------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}