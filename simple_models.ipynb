{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    mean_squared_error,\n",
    "    accuracy_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"joined_data.csv\")\n",
    "\n",
    "\n",
    "data = data.drop([\"id\", \"name\", \"release_date\", \"year\", \"mode\"], axis = 1)\n",
    "X = data.iloc[:,:-1]\n",
    "y = data[\"new_genres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['classical', 'jazz', 'rock', 'country', 'pop', 'edm', 'hip hop',\n",
       "       'alternative', 'metal'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"new_genres\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size = 0.25, random_state = 42)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train = np.array(X)[train_index]\n",
    "    X_test = np.array(X)[test_index]\n",
    "    y_train = np.array(y)[train_index]\n",
    "    y_test = np.array(y)[test_index]\n",
    "    \n",
    "X_train = preprocessing.scale(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/Documents/Northeastern/Spring 2020/ECE2300/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.4295477238267816\n",
      "Train Error: 0.5704522761732185\n",
      "Train Recall: 0.4295477238267816\n",
      "Train Precision: 0.3871955114135871\n",
      "-----------------------------------------\n",
      "Test Accuracy: 0.025915817968004615\n",
      "Test Error: 0.9740841820319954\n",
      "Test Recall: 0.025915817968004615\n",
      "Test Precision: 0.0006716296209507509\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(cv = 5, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)\n",
    "\n",
    "test_pred = clf.predict(X_test)\n",
    "train_pred = clf.predict(X_train)\n",
    "test_acc = (accuracy_score(test_pred, y_test))\n",
    "test_error = 1 - test_acc\n",
    "train_acc = (accuracy_score(train_pred, y_train))\n",
    "train_error = (1 - train_acc)\n",
    "test_prec = precision_score(y_test, test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "train_prec = precision_score(y_train, train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Train Error:\", train_error)\n",
    "print(\"Train Recall:\", train_recall)\n",
    "print(\"Train Precision:\", train_prec)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Error:\", test_error)\n",
    "print(\"Test Recall:\", test_recall)\n",
    "print(\"Test Precision:\", test_prec)\n",
    "print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/Documents/Northeastern/Spring 2020/ECE2300/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Classifiers:\n",
      "Test Accuracy: 0.30056136146797136\n",
      "Test Error: 0.6994386385320286\n",
      "Test Recall: 0.30056136146797136\n",
      "Test Precision: 0.26561348850238303\n",
      "-----------------------------------------\n",
      "Train Accuracy: 0.39959321031026956\n",
      "Train Error: 0.6004067896897305\n",
      "Train Recall: 0.39959321031026956\n",
      "Train Precision: 0.338863321508874\n",
      "-----------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/Documents/Northeastern/Spring 2020/ECE2300/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Classifiers:\n",
      "Test Accuracy: 0.23242139830038386\n",
      "Test Error: 0.7675786016996161\n",
      "Test Recall: 0.23242139830038386\n",
      "Test Precision: 0.2529165382867627\n",
      "-----------------------------------------\n",
      "Train Accuracy: 0.4312636366998262\n",
      "Train Error: 0.5687363633001739\n",
      "Train Recall: 0.4312636366998262\n",
      "Train Precision: 0.39378141223999774\n",
      "-----------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylan/Documents/Northeastern/Spring 2020/ECE2300/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Classifiers:\n",
      "Test Accuracy: 0.0668308593489982\n",
      "Test Error: 0.9331691406510018\n",
      "Test Recall: 0.0668308593489982\n",
      "Test Precision: 0.23901465006236447\n",
      "-----------------------------------------\n",
      "Train Accuracy: 0.43418512628970823\n",
      "Train Error: 0.5658148737102917\n",
      "Train Recall: 0.43418512628970823\n",
      "Train Precision: 0.3989436441934663\n",
      "-----------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_classifiers = [10, 50, 100]\n",
    "\n",
    "for n in n_classifiers:\n",
    "    ada = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth = 1), \n",
    "        n_estimators = n, learning_rate = 1, random_state = 1)\n",
    "    ada.fit(X_train, y_train)\n",
    "    test_pred = ada.predict(X_test)\n",
    "    train_pred = ada.predict(X_train)\n",
    "    test_acc = (accuracy_score(test_pred, y_test))\n",
    "    test_error = 1 - test_acc\n",
    "    train_acc = (accuracy_score(train_pred, y_train))\n",
    "    train_error = (1 - train_acc)\n",
    "    test_prec = precision_score(y_test, test_pred, average='weighted')\n",
    "    test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "    train_prec = precision_score(y_train, train_pred, average='weighted')\n",
    "    train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "    print(n, \"Classifiers:\")\n",
    "    print(\"Test Accuracy:\", test_acc)\n",
    "    print(\"Test Error:\", test_error)\n",
    "    print(\"Test Recall:\", test_recall)\n",
    "    print(\"Test Precision:\", test_prec)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Train Accuracy:\", train_acc)\n",
    "    print(\"Train Error:\", train_error)\n",
    "    print(\"Train Recall:\", train_recall)\n",
    "    print(\"Train Precision:\", train_prec)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Decision Trees:\n",
      "Test Accuracy: 0.2533892475981273\n",
      "Test Error: 0.7466107524018727\n",
      "-----------------------------------------\n",
      "Train Accuracy: 0.7128878369882771\n",
      "Train Error: 0.28711216301172293\n",
      "-----------------------------------------\n",
      "\n",
      "\n",
      "100 Decision Trees:\n",
      "Test Accuracy: 0.3150724444740287\n",
      "Test Error: 0.6849275555259713\n",
      "-----------------------------------------\n",
      "Train Accuracy: 0.712895233164454\n",
      "Train Error: 0.287104766835546\n",
      "-----------------------------------------\n",
      "\n",
      "\n",
      "150 Decision Trees:\n",
      "Test Accuracy: 0.3047771195278351\n",
      "Test Error: 0.695222880472165\n",
      "-----------------------------------------\n",
      "Train Accuracy: 0.712895233164454\n",
      "Train Error: 0.287104766835546\n",
      "-----------------------------------------\n",
      "\n",
      "\n",
      "300 Decision Trees:\n",
      "Test Accuracy: 0.3053318245357119\n",
      "Test Error: 0.694668175464288\n",
      "-----------------------------------------\n",
      "Train Accuracy: 0.712895233164454\n",
      "Train Error: 0.287104766835546\n",
      "-----------------------------------------\n",
      "\n",
      "\n",
      "500 Decision Trees:\n",
      "Test Accuracy: 0.30029510306419044\n",
      "Test Error: 0.6997048969358095\n",
      "-----------------------------------------\n",
      "Train Accuracy: 0.712895233164454\n",
      "Train Error: 0.287104766835546\n",
      "-----------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_trees = [50, 100, 150, 300, 500]\n",
    "\n",
    "for n in n_trees:\n",
    "    rf = RandomForestClassifier(n_estimators = n).fit(X_train, y_train)\n",
    "    test_pred = rf.predict(X_test)\n",
    "    train_pred = rf.predict(X_train)\n",
    "    test_acc = (accuracy_score(test_pred, y_test))\n",
    "    test_error = 1 - test_acc\n",
    "    train_acc = (accuracy_score(train_pred, y_train))\n",
    "    train_error = (1 - train_acc)\n",
    "    #test_prec = precision_score(y_test, test_pred)\n",
    "    #test_recall = recall_score(y_test, test_pred)\n",
    "    #train_prec = precision_score(y_train, train_pred)\n",
    "    #train_recall = recall_score(y_train, train_pred)\n",
    "    print(n, \"Estimators:\")\n",
    "    print(\"Test Accuracy:\", test_acc)\n",
    "    print(\"Test Error:\", test_error)\n",
    "    #print(\"Test Recall:\", test_recall)\n",
    "    #print(\"Test Precision:\", test_prec)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Train Accuracy:\", train_acc)\n",
    "    print(\"Train Error:\", train_error)\n",
    "    #print(\"Train Recall:\", train_recall)\n",
    "    #print(\"Train Precision:\", train_prec)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier().fit(X_train, y_train)\n",
    "\n",
    "test_pred = nn.predict(X_test)\n",
    "train_pred = nn.predict(X_train)\n",
    "test_acc = (accuracy_score(test_pred, y_test))\n",
    "test_error = 1 - test_acc\n",
    "train_acc = (accuracy_score(train_pred, y_train))\n",
    "train_error = (1 - train_acc)\n",
    "test_prec = precision_score(y_test, test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "train_prec = precision_score(y_train, train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Train Error:\", train_error)\n",
    "print(\"Train Recall:\", train_recall)\n",
    "print(\"Train Precision:\", train_prec)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Error:\", test_error)\n",
    "print(\"Test Recall:\", test_recall)\n",
    "print(\"Test Precision:\", test_prec)\n",
    "print(\"-----------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier().fit(X_train, y_train)\n",
    "\n",
    "test_pred = nn.predict(X_test)\n",
    "train_pred = nn.predict(X_train)\n",
    "test_acc = (accuracy_score(test_pred, y_test))\n",
    "test_error = 1 - test_acc\n",
    "train_acc = (accuracy_score(train_pred, y_train))\n",
    "train_error = (1 - train_acc)\n",
    "test_prec = precision_score(y_test, test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "train_prec = precision_score(y_train, train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, train_pred, average='weighted')\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Train Error:\", train_error)\n",
    "print(\"Train Recall:\", train_recall)\n",
    "print(\"Train Precision:\", train_prec)\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"Test Error:\", test_error)\n",
    "print(\"Test Recall:\", test_recall)\n",
    "print(\"Test Precision:\", test_prec)\n",
    "print(\"-----------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}